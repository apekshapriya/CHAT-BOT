{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the data from \n",
    "#chat1 stores the chat of 1st person of training set\n",
    "#chat2 stores the chat of 2nd person of training set\n",
    "\n",
    "#chat3 stores the chat of 1st person of test set\n",
    "#chat4 stores the chat of 2nd person of test set\n",
    "\n",
    "\n",
    "chat1=[]\n",
    "chat2=[]\n",
    "chat3=[]\n",
    "chat4=[]\n",
    "\n",
    "def yield_alt(f, option='odd'):\n",
    "    \n",
    "        if option == 'odd':\n",
    "            return islice(f, 0, None, 2)\n",
    "        return islice(f, 1, None, 2)\n",
    " \n",
    "with open('training_dataset.txt') as f:\n",
    "    for line in yield_alt(f):      \n",
    "        chat1.append(line)\n",
    "\n",
    "with open('training_dataset.txt') as f:\n",
    "    for line in yield_alt(f, 'even'):\n",
    "        chat2.append(line)\n",
    "        \n",
    "with open('test_dataset.txt') as f:\n",
    "    for line in yield_alt(f):      \n",
    "        chat3.append(line)\n",
    "\n",
    "with open('test_dataset.txt') as f:\n",
    "    for line in yield_alt(f, 'even'):\n",
    "        chat4.append(line)\n",
    "\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showing some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hi\\n', 'hello\\n', 'hey\\n', \"what's up\\n\", 'greetings\\n'],\n",
       " ['hi\\n', 'hi\\n', 'hi\\n', 'nothing much\\n', 'greetings\\n'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat1[:5],chat2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['hey\\n',\n",
       "  \"what's up\\n\",\n",
       "  'greetings\\n',\n",
       "  'how are you\\n',\n",
       "  'how are you doing today\\n'],\n",
       " ['hi\\n',\n",
       "  'nothing much\\n',\n",
       "  'greetings\\n',\n",
       "  \"I'm doing good\\n\",\n",
       "  \"I'm doing good\\n\"])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat3[:5],chat4[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chat1),len(chat3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizes the list of strings and finds the vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ques stores the tokenized list of chat1\n",
    "#ans stores tokenized list of chat2\n",
    "#ques1 stores the tokenized list of chat3\n",
    "#ans1 stores tokenized list of chat4\n",
    "\n",
    "#words store total number of words\n",
    "#vocab_stores total number of unique words\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "ques,ans=[],[]\n",
    "words=[]\n",
    "\n",
    "for i in chat1:\n",
    "    \n",
    "        tr=map(str.lower,tokenizer.tokenize(i))\n",
    "        ques.append(tr)\n",
    "        words.extend(tr)\n",
    "        \n",
    "for i in chat2:\n",
    "    \n",
    "        tr=map(str.lower,tokenizer.tokenize(i)) \n",
    "        ans.append(tr)\n",
    "        words.extend(tr)\n",
    "           \n",
    "ques1=[]\n",
    "ans1=[]\n",
    "        \n",
    "for i in chat3:\n",
    "    \n",
    "        tr=map(str.lower,tokenizer.tokenize(i))\n",
    "        ques1.append(tr)\n",
    "        words.extend(tr)\n",
    "        \n",
    "for i in chat4:\n",
    "    \n",
    "        tr=map(str.lower,tokenizer.tokenize(i)) \n",
    "        ans1.append(tr)\n",
    "        words.extend(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ques1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size=len((set(words)))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finds dictionary of words (id to word and word to id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word=dict(enumerate(set(words)))\n",
    "\n",
    "word_to_id={k:v for v,k in id_to_word.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data stores tokenized question and answer as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "\n",
    "a=[data.append(i) for i in ques]\n",
    "a=[data.append(i) for i in ans]\n",
    "a=[data.append(i) for i in ques1]\n",
    "a=[data.append(i) for i in ans1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an empty string to the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds empty string corresponding the index added for padding in the later part part of code\n",
    "\n",
    "id_to_word[vocab_size]=''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting words to indices of ques and ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and target stores the  indices corresponding to words of ques and ans\n",
    "\n",
    "train,target=[],[]\n",
    "test,test_target=[],[]\n",
    "\n",
    "for i in range(len(ques)):\n",
    "    \n",
    "    train.append([word_to_id[x] for x in ques[i]])\n",
    "    target.append([word_to_id[x] for x in ans[i]])\n",
    "\n",
    "for i in range(len(ques1)):\n",
    "    test.append([word_to_id[x] for x in ques1[i]])\n",
    "    test_target.append([word_to_id[x] for x in ans1[i]])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding to make all sequence of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length calculates length of longest sequence and add 100 as a padding to make all sequence of equal length\n",
    "\n",
    "max_length = max([len(i) for i in data])\n",
    "\n",
    "for i in range(len(train)):\n",
    "    \n",
    "    train[i] =[j for j in train[i]] + [vocab_size] * (max_length - len(train[i]))\n",
    "\n",
    "    target[i] =[j for j in target[i]] + [vocab_size] * (max_length - len(target[i]))\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    \n",
    "    test[i] =[j for j in test[i]] + [vocab_size] * (max_length - len(test[i]))\n",
    "\n",
    "    test_target[i] =[j for j in test_target[i]] + [vocab_size] * (max_length - len(test_target[i]))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting list into array to feed in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = np.array(train)\n",
    "\n",
    "target = np.array(target)\n",
    "test = np.array(test)\n",
    "\n",
    "test_target = np.array(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 68, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [125, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [ 60, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128]]),\n",
       " array([[ 68, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [ 68, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [ 68, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3],target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 60, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [ 33,  51,  76, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [  4, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128]]),\n",
       " array([[ 68, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [ 55,  62, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128],\n",
       "        [  4, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "         128, 128]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:3],test_target[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding is used as an embedding vector\n",
    "\n",
    "vec = np.zeros((vocab_size+1, vocab_size+1))\n",
    "\n",
    "for k in id_to_word.keys():\n",
    "    vec[k][k] = 1\n",
    "\n",
    "# constant tensor for word embedding(one hot)\n",
    "\n",
    "embed = tf.constant(vec, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size+1\n",
    "output_size = vocab_size+1\n",
    "iterations = 5001\n",
    "hidden_layer = 60\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializing random weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Wxhe=tf.Variable(tf.random_normal(([input_size,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whhe=tf.Variable(tf.random_normal(([hidden_layer,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whye=tf.Variable(tf.random_normal(([hidden_layer,output_size]),0,0.1),dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxhd=tf.Variable(tf.random_normal(([189,60]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whhd=tf.Variable(tf.random_normal(([hidden_layer,hidden_layer]),0,0.1),dtype=tf.float32)\n",
    "\n",
    "Whyd=tf.Variable(tf.random_normal(([120,output_size]),0,0.1),dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to train the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(): # execution of training starts with this function\n",
    "    \n",
    "    with tf.variable_scope(\"train_nn\"):\n",
    "        \n",
    "        #placeholder for input, output and hidden state and previous outputs of encoder and decoder\n",
    "        loss_plot,itr=[],[]\n",
    "        \n",
    "        x=tf.placeholder(shape=[None,max_length], dtype=tf.int32) \n",
    "        y=tf.placeholder(shape=[None,None],dtype=tf.int32)\n",
    "        \n",
    "        hinit = tf.placeholder(shape=[None, hidden_layer], dtype=tf.float32)\n",
    "        \n",
    "        xinit=tf.placeholder(shape=[None,vocab_size+1],dtype=tf.float32)\n",
    "        \n",
    "        prob=tf.placeholder(shape=[None,vocab_size+1],dtype=tf.float32)\n",
    "        \n",
    "        context_vec=tf.placeholder(shape=[None,hidden_layer],dtype=tf.float32)\n",
    "\n",
    "        #embedding target as one hot\n",
    "        Y_embed = tf.nn.embedding_lookup(embed,y)\n",
    "\n",
    "        # encoder_output is the context vector and encoder state is the hidden state of lat time space\n",
    "        encoder_output,encoder_states,last_ht=encoder(x,hinit,xinit)\n",
    "\n",
    "        #decoder_output is the output of decoder(as an output of softmax layer)\n",
    "        decoder_output=decoder(x,encoder_output,tf.transpose(encoder_states,[1,0,2]),prob,last_ht,context_vec)\n",
    "        decoder_output = tf.transpose(decoder_output, [1, 0, 2])\n",
    "        \n",
    "        #takes the argmax of output to find the indices of the corresponding word \n",
    "        decoder_output_arg=tf.argmax(decoder_output,axis=2)\n",
    "        one_hot_out=tf.nn.embedding_lookup(embed,(tf.cast(decoder_output_arg, tf.int32)))\n",
    "        \n",
    "        #loss takes the mean of all the samples loss (loss function used is softmax_cross_entropy_with_logits)\n",
    "        loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=decoder_output,labels=Y_embed))\n",
    "        \n",
    "        optimizer=tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "        \n",
    "        with tf.Session() as session:\n",
    "\n",
    "            session.run(tf.global_variables_initializer()) #initializes the variables\n",
    "            session.run(tf.local_variables_initializer())\n",
    "            \n",
    "            #iterating the loop\n",
    "            for i in range(60001):\n",
    "                \n",
    "                #runs the loss and optimizer function by feeding train, target and hidden state to their placeholders \n",
    "                #l is the loss at each iteration\n",
    "                \n",
    "                l,_=session.run([loss,optimizer],\n",
    "                feed_dict={x:train, y:target,hinit:np.zeros((30,hidden_layer)),xinit:np.zeros((30,vocab_size+1))\n",
    "                    ,prob:np.zeros((30,vocab_size+1)),context_vec:np.zeros((30,hidden_layer))})\n",
    "                \n",
    "                loss_plot.append(l)\n",
    "                itr.append(i)\n",
    "                \n",
    "                if i%1000==0:\n",
    "                    print \"loss for\",i,\"iteration:\",l\n",
    "                    loss_plot.append(l)\n",
    "                    itr.append(i)\n",
    "                \n",
    "                #predict outputs the decoders output after each weight tuning at each iteration\n",
    "                \n",
    "                \n",
    "                    predict = session.run(decoder_output_arg,\n",
    "                    {x:train, y:target,hinit:np.zeros((30,hidden_layer)),xinit:np.zeros((30,vocab_size+1)),\n",
    "                     prob:np.zeros((30,vocab_size+1)),context_vec:np.zeros((30,hidden_layer))})\n",
    "                \n",
    "                if(i%5000==0):\n",
    "                    \n",
    "                    \n",
    "                    for j in range(20,29):#print predicted result of training 10 sample \n",
    "\n",
    "                        print(\"chat1 : \", [[id_to_word[w] for w in sent] for sent in train][j])\n",
    "                        print(\"chat2 : \", [[id_to_word[w] for w in sent] for sent in predict][j])\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "            print\"---------Training over------------\"\n",
    "            \n",
    "            print \"---testing the trained model with test data----\"\n",
    "            \n",
    "            out_test = session.run(decoder_output_arg, {x:test, \n",
    "                hinit: np.zeros((33, hidden_layer)),xinit:np.zeros((33,vocab_size+1)),\n",
    "                prob:np.zeros((33,vocab_size+1)),context_vec:np.zeros((33,hidden_layer))})\n",
    "            \n",
    "            for k in range(33):#print predicted result of test samples\n",
    "\n",
    "                        print(\"chat1 : \", [[id_to_word[w] for w in sent] for sent in test][k])\n",
    "                        print(\"chat2 : \", [[id_to_word[w] for w in sent] for sent in out_test][k])\n",
    "                        \n",
    "            #calculating accuracy of test samples\n",
    "                        \n",
    "            correct_pred=tf.equal(out_test,test_target)\n",
    "            \n",
    "            accuracy=tf.reduce_mean(tf.cast(correct_pred,'float'))  \n",
    "            \n",
    "            a=accuracy.eval(feed_dict={x:test, y:test_target,\n",
    "                hinit: np.zeros((33, hidden_layer)),xinit:np.zeros((33,vocab_size+1)),\n",
    "                prob:np.zeros((33,vocab_size+1)),context_vec:np.zeros((33,hidden_layer))})\n",
    "            \n",
    "            print \"accuracy of test samples\",a\n",
    "                        \n",
    "            return loss_plot,itr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## encoder function to find the context vector and hidden state of input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(X,hinit,xinit):#takes input sequence and initial hidden state and initial output \n",
    "    \n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        \n",
    "        #embedding for train to one hot\n",
    "        X_embed = tf.nn.embedding_lookup(embed,X)\n",
    "        X_embed = tf.transpose(X_embed, [1, 0, 2])\n",
    "\n",
    "        #list of hidden state and output\n",
    "        con=[hinit,xinit]\n",
    "        \n",
    "        #scans encoder's helper function RNN_enc \n",
    "        output= tf.scan(RNN_enc, X_embed, initializer=con)\n",
    "  \n",
    "        \n",
    "        h_t=output[0]\n",
    "        y_t=output[1]\n",
    "        \n",
    "        last_ht=h_t[-1]\n",
    "        y_t=y_t[-1]\n",
    "\n",
    "        \n",
    "        arg=tf.argmax(y_t,axis=1)\n",
    "        arg_one_hot=tf.nn.embedding_lookup(embed,(tf.cast(arg, tf.int32)))\n",
    "        \n",
    "        #returns one hot vector of encoder's output and hidden state\n",
    "        return arg_one_hot,h_t,last_ht\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder's helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_enc(h, x_t):#helper function of encoder (takes hidden states,output and input sequence)\n",
    "    \n",
    "    with tf.variable_scope('RNN_enc'):\n",
    "        \n",
    "            #reshapes input sequence\n",
    "            x_t = tf.reshape(x_t, [-1, input_size])\n",
    "            x_t=tf.cast(x_t, tf.float32)\n",
    "\n",
    "            #reshapes hidden state\n",
    "            hprev = tf.reshape(h[0], [-1, hidden_layer])\n",
    "\n",
    "            #h_t calculates the wighted sum of inputs and hidden  state of previous layes \n",
    "            #and then pass it to the activation function\n",
    "            \n",
    "            h_t=tf.tanh(tf.matmul(hprev,Whhe) + tf.matmul(x_t,Wxhe))\n",
    "            h_t = tf.reshape(h_t, [-1, hidden_layer])\n",
    "\n",
    "            #out is the output from the softmax layer\n",
    "            out=tf.nn.softmax(tf.matmul(h_t,Whye))\n",
    "\n",
    "\n",
    "            x_and_h=[h_t,out]        \n",
    "\n",
    "            #reurns list of hidden state and ouput of encoder\n",
    "            return x_and_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(X,xprev,s,prob,last_ht,context_vec):\n",
    "    \n",
    "    #takes input sequence  \n",
    "    #last hidden state from encoder \n",
    "    #hidden states of encoder\n",
    "    #initial input to decoder \n",
    "    #context vector\n",
    "    \n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        \n",
    "        #embedding for train to one hot\n",
    "        X_embed = tf.nn.embedding_lookup(embed,X)\n",
    "        X_embed = tf.transpose(X_embed, [1, 0, 2])\n",
    "\n",
    "        #list of hidden states,output of previous state\n",
    "        con=[s,xprev,prob,last_ht,context_vec]\n",
    "\n",
    "        #scans decoder's helper function RNN_enc \n",
    "        output= tf.scan(RNN_dec, X_embed, initializer=con)\n",
    "\n",
    "        h_dec=output[0]\n",
    "\n",
    "        out_prob=output[2]\n",
    "        \n",
    "        #returns output from decoder\n",
    "        return out_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder's helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_dec(h, x_t):\n",
    "    \n",
    "     #takes hidden state of previous time state\n",
    "     #ouput of previous state\n",
    "     #input sequence just for the sake of working of scan function to iterate\n",
    "     #all hidden states of encoder\n",
    "     #context vector\n",
    "        \n",
    "        with tf.variable_scope('RNN_dec'):\n",
    "            \n",
    "            hprev=h[3]\n",
    "            yprev=h[1]\n",
    "            enc_state=h[0]\n",
    "            context=h[4]\n",
    "            \n",
    "            #reshape\n",
    "            hprev = tf.reshape(hprev, [-1, hidden_layer])\n",
    "\n",
    "            yprev = tf.reshape(yprev, [-1, input_size])\n",
    "            \n",
    "            \n",
    "            #h_t calculates the wighted sum of inputs and hidden  state of previous layes \n",
    "            #and then pass it to the activation function\n",
    "            \n",
    "            y_and_c=tf.concat([yprev,context],axis=1)\n",
    "            \n",
    "            h_t=tf.tanh(tf.matmul(y_and_c,Wxhd)+tf.matmul(hprev,Whhd))\n",
    "            h_t = tf.reshape(h_t, [-1, hidden_layer])\n",
    "\n",
    "            \n",
    "            attention_score=tf.multiply(enc_state,tf.expand_dims(h_t, 1))  \n",
    "            \n",
    "            \n",
    "            attention_score=tf.transpose(attention_score,[0,2,1])\n",
    "            \n",
    "            attention_score=tf.reduce_sum(attention_score,axis=1)\n",
    "            \n",
    "            attention_score=tf.nn.softmax(attention_score)\n",
    "            \n",
    "            \n",
    "            \n",
    "            context=tf.multiply(tf.transpose(enc_state,[0,2,1]),tf.expand_dims(attention_score,1))\n",
    "             \n",
    "            \n",
    "            context=tf.reduce_sum(tf.transpose(context,[0,2,1]),axis=1)\n",
    "            \n",
    "            \n",
    "            con=tf.concat([h_t,context],axis=1)\n",
    "            \n",
    "            #out is the output from the softmax layer\n",
    "            out=tf.nn.softmax(tf.matmul(con,Whyd))\n",
    "            \n",
    "            arg=tf.argmax(out,axis=1)\n",
    "            arg_one_hot=tf.nn.embedding_lookup(embed,arg)\n",
    "\n",
    "            x_and_h=[enc_state,arg_one_hot,out,h_t,context] \n",
    "            \n",
    "            #reurns list of hidden states,context vector and ouput of decoder\n",
    "            return x_and_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to start the execution of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for 0 iteration: 4.85965\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'switzerland', '', 'may', 'am', 'urgent', 'station', 'station', 'i', 'sure', 'urgent', 'station', 'hi', 'on', 'in'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'switzerland', '', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'switzerland', '', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'switzerland', '', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'in'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['station', 'switzerland', '', 'depends', 'urgent', 'by', 'station', 'fill', 'depends', 'depends', 'on', '5mins', 'station', 'number', 'depends'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'terminus', 'doctor', 'below', 'the', 'depends', 'station', 'nameless', 'my', 'hi', '40mins', 'in', '40mins', '40mins', 'today'])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'terminus', 'doctor', 'depends', 'terminus', '', 'station', 'station', 'i', 'depends', 'depends', 'terminus', 'doctor', 'doctor', 'terminus'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'switzerland', '', 'depends', 'depends', 'want', '5mins', 'name', 'depends', 'nameless', 'on', 'form', 'if', 'form', 'depends'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['needs', 'form', 'station', 'my', 'depends', 'station', 'only', 'depends', 'who', 'fill', 'depends', 'talk', 'on', 'bordeaux', 'whenever'])\n",
      "loss for 1000 iteration: 4.31974\n",
      "loss for 2000 iteration: 4.31972\n",
      "loss for 3000 iteration: 4.31971\n",
      "loss for 4000 iteration: 4.31971\n",
      "loss for 5000 iteration: 4.31971\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 6000 iteration: 4.31971\n",
      "loss for 7000 iteration: 4.31971\n",
      "loss for 8000 iteration: 4.2997\n",
      "loss for 9000 iteration: 4.28183\n",
      "loss for 10000 iteration: 4.27728\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'need', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'need', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'need', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'need', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'about', 'nameless', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'about', 'nameless', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'i', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'i', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['take', 'about', 'nameless', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 11000 iteration: 4.27502\n",
      "loss for 12000 iteration: 4.28671\n",
      "loss for 13000 iteration: 4.23733\n",
      "loss for 14000 iteration: 4.22827\n",
      "loss for 15000 iteration: 4.20174\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'the', 'periph', 'the', 'and', 'the', 'and', 'the', 'and'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'the', 'periph', 'the', 'and', 'the', 'and', 'the', 'and'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'the', 'periph', 'the', 'and', 'the', 'and', 'the', 'and'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'depends', 'on', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'can', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 16000 iteration: 4.19267\n",
      "loss for 17000 iteration: 4.18162\n",
      "loss for 18000 iteration: 4.16831\n",
      "loss for 19000 iteration: 4.15724\n",
      "loss for 20000 iteration: 4.15272\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'and', 'for', 'for', 'periph', 'and', 'for', 'periph', 'your'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'and', 'for', 'for', 'the', 'the', 'periph', 'and', 'for'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'and', 'for', 'for', 'the', 'the', 'periph', 'and', 'for'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'me', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['whenever', 'please', 'come', 'to', 'i', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 21000 iteration: 4.13276\n",
      "loss for 22000 iteration: 4.12827\n",
      "loss for 23000 iteration: 4.1238\n",
      "loss for 24000 iteration: 4.11978\n",
      "loss for 25000 iteration: 4.1127\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', '30mins', 'for', 'drive', 'drive', 'drive'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', '30mins', 'for', 'drive', 'drive', 'drive'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', '30mins', 'for', '30mins', 'drive', 'drive'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'you', 'come', 'to', 'you', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 26000 iteration: 4.1083\n",
      "loss for 27000 iteration: 4.09937\n",
      "loss for 28000 iteration: 4.09048\n",
      "loss for 29000 iteration: 4.07715\n",
      "loss for 30000 iteration: 4.133\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'away', 'away', 'from', 'there', 'from'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'away', 'away', 'from', 'there', 'from'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'away', 'away', 'from', 'there', 'from'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'the', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'away', 'away', 'from', 'there', 'from'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'number', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'you', 'come', 'to', 'fill', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 31000 iteration: 4.09954\n",
      "loss for 32000 iteration: 4.09951\n",
      "loss for 33000 iteration: 4.09948\n",
      "loss for 34000 iteration: 4.09947\n",
      "loss for 35000 iteration: 4.09749\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'and', 'the', 'at', 'and', 'drive', 'for', '30mins', 'station', 'away', 'from', 'there', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'station', 'away', 'from', 'there', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'station', 'away', 'from', 'there', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'and', 'the', 'periph', 'and', 'drive', 'for', '30mins', 'station', 'away', 'from', 'there', 'subway'])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'how', 'their', 'urgent', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['below', 'you', 'come', 'to', 'urgent', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 36000 iteration: 4.08398\n",
      "loss for 37000 iteration: 4.05056\n",
      "loss for 38000 iteration: 4.04832\n",
      "loss for 39000 iteration: 4.04607\n",
      "loss for 40000 iteration: 4.03285\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'drive', 'train', 'train', 'train', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'have', '', 'address', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['have', 'you', 'come', 'to', 'me', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 41000 iteration: 4.02375\n",
      "loss for 42000 iteration: 4.01962\n",
      "loss for 43000 iteration: 4.01497\n",
      "loss for 44000 iteration: 4.01488\n",
      "loss for 45000 iteration: 4.01485\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'drive', 'paris', 'train', 'station', 'we', 'we', 'below', 'train'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['greetings', 'you', 'come', 'to', 'me', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 46000 iteration: 4.01261\n",
      "loss for 47000 iteration: 4.0105\n",
      "loss for 48000 iteration: 4.0082\n",
      "loss for 49000 iteration: 4.00818\n",
      "loss for 50000 iteration: 4.00376\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'paris', 'paris', 'train', 'station', 'we', 'are', 'are', 'then'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'on', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['need', 'you', 'come', 'to', 'me', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 51000 iteration: 4.00149\n",
      "loss for 52000 iteration: 3.99926\n",
      "loss for 53000 iteration: 3.99924\n",
      "loss for 54000 iteration: 3.99921\n",
      "loss for 55000 iteration: 3.9904\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'subway', 'paris', 'train', 'station', 'we', 'subway', 'subway', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'terminus', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['need', 'you', 'come', 'to', 'assistant', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "loss for 56000 iteration: 3.99038\n",
      "loss for 57000 iteration: 3.98817\n",
      "loss for 58000 iteration: 3.98594\n",
      "loss for 59000 iteration: 3.98593\n",
      "loss for 60000 iteration: 3.98372\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'switzerland', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'is', 'paris', 'train', 'station', 'away', 'someone', '5mins', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'car', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'bike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'is', 'the', 'doctor', 'free', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'you', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'renew', 'my', 'prescription', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['30mins', 'you', 'come', 'to', 'greetings', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "---------Training over------------\n",
      "---testing the trained model with test data----\n",
      "('chat1 : ', ['hey', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['hi', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['what', 's', 'up', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['nothing', 'much', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['greetings', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['greetings', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'are', 'you', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'm', 'doing', 'good', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'are', 'you', 'doing', 'today', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'm', 'doing', 'good', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['what', 's', 'your', 'name', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'm', 'nameless', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['what', 'can', 'you', 'do', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['anything', 'that', 'you', 'want', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'may', 'i', 'check', 'in', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'date', 'want', 'on', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'will', 'i', 'be', 'able', 'to', 'i', 'check', 'out', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'date', 'want', 'on', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['who', 'are', 'you', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'am', 'your', 'little', 'assistant', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['hi', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['hi', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['hello', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['hi', '', '', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['what', 's', 'your', 'address', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'don', 't', 'have', 'an', 'address', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['what', 's', 'your', 'phone', 'number', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['i', 'don', 't', 'have', 'an', 'number', 'either', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'can', 'i', 'call', 'you', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['30mins', 'can', 't', 'call', 'me', 'how', 'only', 'only', 'only', 'metro', 'me', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'can', 'i', 'contact', 'you', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['below', 'can', 't', 'call', 'me', 'have', 'either', 'only', 'on', 'on', 'me', '', '', '', ''])\n",
      "('chat1 : ', ['can', 'you', 'call', 'someone', 'for', 'me', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'what', 'is', 'their', 'phone', 'number', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['can', 'i', 'talk', 'to', 'someone', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['doing', '', 'below', 'getting', 'then', 'someone', 'to', 'date', '5mins', 'to', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'stop', 'at', 'subway', 'subway', 'we', 'are', '5mins', 'away', 'from', 'there', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'bordeaux', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'is', 'paris', 'train', 'station', 'away', 'someone', '5mins', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'from', 'lyon', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'tgv', 'then', 'is', 'paris', 'train', 'station', 'away', 'someone', '5mins', 'subway'])\n",
      "('chat1 : ', ['how', 'to', 'come', 'to', 'your', 'locals', 'if', 'i', 'come', 'from', 'brazil', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'there', 'from', 'switzerland', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'stop', 'at', 'subway', 'paris', 'we', 'are', '5mins', 'away', 'from', 'there', ''])\n",
      "('chat1 : ', ['how', 'to', 'go', 'to', 'your', 'office', 'by', 'car', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['how', 'to', 'come', 'to', 'your', 'office', 'riding', 'bike', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'stop', 'at', 'train', 'someone', 'we', 'are', '5mins', 'away', 'from', 'there', ''])\n",
      "('chat1 : ', ['how', 'to', 'get', 'to', 'your', 'office', 'if', 'i', 'come', 'by', 'motobike', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'need', 'to', 'take', 'the', 'periph', 'and', 'drive', 'for', '30mins', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'see', 'the', 'doctor', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['when', 'can', 'the', 'doctor', 'be', 'free', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'depends', 'on', 'how', 'urgent', 'you', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'a', 'new', 'prescription', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['well', 'm', 'come', 'to', 'urgent', 'clinic', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['i', 'need', 'to', 'make', 'an', 'appointment', 'for', 'my', 'husband', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'about', 'what', '', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['my', 'husband', 'need', 'to', 'make', 'an', 'appointment', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['you', 'address', 'to', 'getting', 'drive', 'for', '30mins', '', '', '', '', '', '', '', ''])\n",
      "('chat1 : ', ['my', 'child', 'needs', 'a', 'check', 'up', '', '', '', '', '', '', '', '', ''])\n",
      "('chat2 : ', ['sure', 'much', 'come', 'either', '', 'address', 'you', 'greetings', 'the', 'you', 'greetings', 'the', 'you', 'greetings', 'the'])\n",
      "accuracy of test samples 0.79596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/simplejson/encoder.py:269: DeprecationWarning: Interpreting naive datetime as local 2017-04-20 11:11:47.554826. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "#start of execution of training\n",
    "loss,it=train_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(it,loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
